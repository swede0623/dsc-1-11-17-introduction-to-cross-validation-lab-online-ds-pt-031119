{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to practice your cross-validation skills!\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Compare the results with normal holdout validation\n",
    "- Apply 5-fold cross validation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "This time, let's only include the variables that were previously selected using recursive feature elimination. We included the code to preprocess below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "logb = np.log(boston_features[\"B\"])\n",
    "logdis = np.log(boston_features[\"DIS\"])\n",
    "loglstat = np.log(boston_features[\"LSTAT\"])\n",
    "rm = boston_features['RM']\n",
    "\n",
    "# minmax scaling\n",
    "boston_features[\"B\"] = (logb-min(logb))/(max(logb)-min(logb))\n",
    "boston_features[\"DIS\"] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "#standardization\n",
    "boston_features[\"LSTAT\"] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))\n",
    "boston_features['RM'] = (rm-np.mean(rm))/np.sqrt(np.var(rm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_features[['B', 'DIS', 'LSTAT', 'RM', 'CHAS']]\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "\n",
    "Perform a train-test-split with a test set of 0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and apply the model to the make test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the residuals and the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.620931335053108 18.00798227973473\n"
     ]
    }
   ],
   "source": [
    "mse_train = mean_squared_error(y_train, y_hat_train)\n",
    "mse_test = mean_squared_error(y_test, y_hat_test)\n",
    "print(mse_train, mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: let's build it from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross-validation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function k-folds that splits a dataset into k evenly sized pieces.\n",
    "If the full dataset is not divisible by k, make the first few folds one larger then later ones.\n",
    "\n",
    "We want the folds to be a list of subsets of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "667//9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "667%9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "83, 330\n",
    "83, 247\n",
    "83, \n",
    "\n",
    "75,    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds(data, k):\n",
    "    # Force data as pandas dataframe\n",
    "    # add 1 to fold size to account for leftovers     \n",
    "    \n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    fold_size = len(data)//k\n",
    "    leftover = len(data)%k\n",
    "    \n",
    "    times_fold = k-leftover\n",
    "    times_fold_plus_one = leftover\n",
    "    \n",
    "    print(times_fold, times_fold_plus_one)\n",
    "    \n",
    "    folds = []\n",
    "\n",
    "    for i in range(times_fold):\n",
    "        print(i*fold_size, (i+1)*fold_size)\n",
    "        folds.append(data[i*fold_size:(i+1)*fold_size])\n",
    "    \n",
    "    if times_fold_plus_one > 0:\n",
    "        \n",
    "        for i in range(times_fold_plus_one):\n",
    "            print('in plus 1 for loop')\n",
    "            start = times_fold*fold_size\n",
    "            print(start + (i*(fold_size+1)), start+((i+1)*(fold_size+1)))\n",
    "            folds.append(data[start + (i*(fold_size+1)):start+((i+1)*(fold_size+1))])\n",
    "        \n",
    "    return folds    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply it to the Boston Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>DIS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.542096</td>\n",
       "      <td>-1.275260</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>-0.263711</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998553</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>-1.627858</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999195</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>-2.153192</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>-1.162114</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          B       DIS     LSTAT        RM  CHAS  MEDV\n",
       "0  1.000000  0.542096 -1.275260  0.413672   0.0  24.0\n",
       "1  1.000000  0.623954 -0.263711  0.194274   0.0  21.6\n",
       "2  0.998553  0.623954 -1.627858  1.282714   0.0  34.7\n",
       "3  0.999195  0.707895 -2.153192  1.016303   0.0  33.4\n",
       "4  1.000000  0.707895 -1.162114  1.228577   0.0  36.2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to concatenate the data again\n",
    "boston_five_best = pd.concat([X,pd.Series(y, name='MEDV')], axis=1)\n",
    "boston_five_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "0 101\n",
      "101 202\n",
      "202 303\n",
      "303 404\n",
      "in plus 1 for loop\n",
      "404 506\n"
     ]
    }
   ],
   "source": [
    "folds = kfolds(boston_five_best, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 405 entries, 0 to 505\n",
      "Data columns (total 6 columns):\n",
      "B        405 non-null float64\n",
      "DIS      405 non-null float64\n",
      "LSTAT    405 non-null float64\n",
      "RM       405 non-null float64\n",
      "CHAS     405 non-null float64\n",
      "MEDV     405 non-null float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 22.1 KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_popped = folds[:1]+folds[2:]\n",
    "test = pd.concat(test_popped)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a linear regression for each fold, and calculate the training and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform linear regression on each and calculate the training and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.124483087969228, 22.99697588523474, 19.614344728130472, 15.758258008483033, 22.319482832653986]\n",
      "[13.413115726910467, 17.372864299175315, 37.65686446904524, 54.91912185933499, 21.363986528700725]\n",
      "28.945190576633347\n"
     ]
    }
   ],
   "source": [
    "test_errs = []\n",
    "train_errs = []\n",
    "k=5\n",
    "\n",
    "for n in range(k):\n",
    "    # Split in train and test for the fold\n",
    "    train = folds[:n] + folds[n+1:]\n",
    "    train_df = pd.concat(train)\n",
    "    train_X = train_df[['B', 'DIS', 'LSTAT', 'RM', 'CHAS']]\n",
    "    train_y = train_df[\"MEDV\"]\n",
    "    \n",
    "    test = folds[n]\n",
    "    test_df = pd.DataFrame(test)\n",
    "    test_X = test[['B', 'DIS', 'LSTAT', 'RM', 'CHAS']]\n",
    "    test_y = test[\"MEDV\"]\n",
    "    \n",
    "    # Fit a linear regression model\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(train_X, train_y)\n",
    "    \n",
    "    #Evaluate Train and Test Errors\n",
    "    y_hat_train = linreg.predict(train_X)\n",
    "    y_hat_test = linreg.predict(test_X)\n",
    "    \n",
    "    mse_train = mean_squared_error(train_y, y_hat_train)\n",
    "    mse_test = mean_squared_error(test_y, y_hat_test)\n",
    "    \n",
    "    train_errs.append(mse_train)\n",
    "    test_errs.append(mse_test)\n",
    "\n",
    "print(train_errs)\n",
    "print(test_errs)\n",
    "print(np.mean(test_errs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a bit of work! Now, let's perform 5-fold cross-validation to get the mean squared error through scikit-learn. Let's have a look at the five individual MSEs and explain what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_features[['B', 'DIS', 'LSTAT', 'RM', 'CHAS']]\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-13.34501376, -17.66139356, -37.13346086, -55.08461959,\n",
       "       -21.22956376])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results = cross_val_score(linreg, X, y, cv=5, scoring='neg_mean_squared_error' )\n",
    "cv_5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wild fluctuation across results means these data folds vary wildly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the mean of the MSE over the 5 cross-validations and compare and contrast with the result from the train-test-split case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.890810306821628"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(np.mean(cv_5_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the test_mse for the train-test-split case was 18.  that's a huge difference.  I guess that shows if data has huge ranges within itself, it can lead to unreliable linear regression accuracy statistics unless care is taken with the training and test splits (cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now practiced your knowledge on k-fold crossvalidation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
